##Information Theory
1- Grokking as Compression: A Nonlinear Complexity Perspective 
  https://arxiv.org/pdf/2310.05918.pdf 
2-  In search of dispersed memories: Generative diffusion models are associative memory networks
https://arxiv.org/abs/2309.17290
3- White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?
  https://arxiv.org/pdf/2311.13110.pdf
  

## Anthropic Mechanistic Interpretability
+ https://transformer-circuits.pub/2023/monosemantic-features/index.html

## Untagged 
+ LANGUAGE MODELS REPRESENT SPACE AND TIME
 https://arxiv.org/pdf/2310.02207.pdf
+ Beyond Surface Statistics : https://arxiv.org/pdf/2306.05720.pdf

## Category Theory

## In Context Learning Mystery
+ In-Context Learning Creates Task Vectors: https://arxiv.org/pdf/2310.15916.pdf

## Optimal Transort
+ https://www.youtube.com/watch?v=EauDdCzxphE

## Geometry and Topology in Machine Learning
+ https://www.youtube.com/watch?v=sS8zRGgPLNc
+ Meaning comes from geometry most of the time.


## Dead neurons Question/ Mystery
+ https://lena-voita.github.io/posts/neurons_in_llms_dead_ngram_positional.html 
   + https://arxiv.org/pdf/2309.04827.pdf
## Physic models in DL
+ https://www.youtube.com/watch?v=XLNmgviQHPA LEGO paper
+ 
